{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the .csv containing the file names and the steering angles\n",
    "\n",
    "### Loading the file names  and steering angles into samples\n",
    "### Splitting samples into train and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def  extractFileName ( ssd_folder, abs_path):\n",
    "#     print (abs_path)\n",
    "\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "        \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "#         print (\"windows path \")\n",
    "        image_name = ssd_folder\\\n",
    "                    +split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                    + split_char +abs_path.split ('\\\\')[-1]\n",
    "#         print (image_name)\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = ssd_folder \\\n",
    "                     + split_char + abs_path.split ('/')[-2] \\\n",
    "                     + split_char + abs_path.split ('/')[-1]\n",
    "#         print ( \"image_name = \" + image_name)\n",
    "    \n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy data folder to ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_folder = \"/ssd_data/project3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil \n",
    "\n",
    "# shutil.rmtree(ssd_folder)\n",
    "# print ( \"Copying files to ssd ....\")\n",
    "# shutil.copytree (\"data\",ssd_folder)\n",
    "# print ( \"... completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Sample Pytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The file '/ssd_data/project3/samples.hdf5' is already opened.  Please close it before reopening in write mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cc32f633c907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhdf5_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mssd_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/samples.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Samples\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 raise ValueError(\n\u001b[1;32m    316\u001b[0m                     \u001b[0;34m\"The file '%s' is already opened.  Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                     \"close it before reopening in write mode.\" % filename)\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The file '/ssd_data/project3/samples.hdf5' is already opened.  Please close it before reopening in write mode."
     ]
    }
   ],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "hdf5_file = open_file(ssd_folder + \"/samples.hdf5\", mode = \"w\", title = \"Samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the batch size:\n",
    "batch_size = 128\n",
    "\n",
    "### Defining the Queue loader chunk size  \n",
    "queue_loader_chunk = 100 # batch_size(32) * 1000 samples, = 32000 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = /ssd_data/project3/run5.csv\n",
      "Reading from logfile = /ssd_data/project3/run3.csv\n",
      "Reading from logfile = /ssd_data/project3/run4.csv\n",
      "Reading from logfile = /ssd_data/project3/track1_run1.csv\n",
      "Reading from logfile = /ssd_data/project3/run2.csv\n",
      "Reading from logfile = /ssd_data/project3/run1.csv\n",
      "\n",
      "\n",
      "There are 15909 images in total \n",
      "....splitted into training images = 12727  \n",
      "                  val images      = 3182  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(ssd_folder + \"/*.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                # STEERING ANGLE CALCULATION\n",
    "                samples_list.append([extractFileName(ssd_folder, line[0]),\\\n",
    "                                     extractFileName(ssd_folder, line[1]),\\\n",
    "                                     extractFileName(ssd_folder, line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "samples_list = np.array(samples_list)\n",
    "\n",
    "# from random import shuffle\n",
    "# shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.8*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.8*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_list[3400:3700 ]\n",
    "# train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_list = val_list[0:10]\n",
    "# val_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.2 # 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( ssd_folder, line[0]))\n",
    "#         print (extractFileName(ssd_folder,  line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName(ssd_folder,  line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName(ssd_folder,  line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "#         ###\n",
    "#         ### IMAGE AUGMENTATION\n",
    "#         ###\n",
    "#         # augmented center image\n",
    "#         preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "#         # augmented left image\n",
    "#         preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "#         # augmented right image\n",
    "#         preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing using the function defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,sample_line in enumerate(train_list):\n",
    "#    print ( \" steering \" + sample_line[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preprocessing the images  .... \n",
      ".. training samples processed 1000\n",
      ".. training samples processed 2000\n",
      ".. training samples processed 3000\n",
      ".. training samples processed 4000\n",
      ".. training samples processed 5000\n",
      ".. training samples processed 6000\n",
      ".. training samples processed 7000\n",
      ".. training samples processed 8000\n",
      ".. training samples processed 9000\n",
      ".. training samples processed 10000\n",
      ".. training samples processed 11000\n",
      ".. training samples processed 12000\n",
      ".. validation samples processed 1000\n",
      ".. validation samples processed 2000\n",
      ".. validation samples processed 3000\n",
      "\n",
      "Total training samples 128x128 after augmentation and preprocessing : 38181 \n",
      "\n",
      "Total validation samples 128x128 after augmentation and preprocessing : 9546 \n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "training_samples      =  []\n",
    "validation_samples =  []\n",
    "training_steerings = []\n",
    "validation_steerings = []\n",
    "\n",
    "for i,sample_line in enumerate(train_list):\n",
    "#    print (i)\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print (output[0].shape)\n",
    "        try:\n",
    "            training_samples.append(output[0])\n",
    "            training_steerings.append(output[1])\n",
    "        except ValueError:\n",
    "            print (\" Image not found \" +sample_line[0] )\n",
    "            \n",
    "   if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "   \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print ( \"output[0].shape\" + str(output[0].shape))\n",
    "        validation_samples.append(output[0])\n",
    "        validation_steerings.append(output[1])\n",
    "#         print (output[0][None].shape)\n",
    "\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(training_samples)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(validation_samples)) ))\n",
    "print ( \"... completed\")\n",
    "\n",
    "training_samples = np.array(training_samples)\n",
    "validation_samples = np.array(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38181, 128, 128, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38181"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_steerings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for steering in training_steering:\n",
    "#     print ( \"steering = \" + str(steering ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20, 200))\n",
    "# plt.subplot(50, 4, 1 )\n",
    "# plt.axis('off')\n",
    "# for i, image in enumerate(py_training_samples):\n",
    "#        plt.subplot(50, 4, i+2 )\n",
    "#        plt.axis('off')\n",
    "#        plt.imshow(image, cmap='gray')\n",
    "# plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(val_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to simulate a \"Recurrent neural network\"\n",
    "#### inserting previous 3  images with current steering wheel angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ( \"Starting Preprocessing the images  .... \")\n",
    "\n",
    "# for i,sample_line in enumerate(train_list):\n",
    "#    if i > 10: \n",
    "#        current_steering_angle = sample_line[3]\n",
    "#        for ix in range ( i-1 , i-4 , -1):\n",
    "#            sample_line_prev  = [train_list[ix][0],train_list[ix][1],train_list[ix][2],current_steering_angle]\n",
    "#            for output in data_preprocess(sample_line_prev):\n",
    "#                 py_training_samples.append(output[0][None])\n",
    "#                 training_steering.append(output[1])\n",
    "          \n",
    "#    if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "    \n",
    "\n",
    "# print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "#        .format(resized_shape,resized_shape,\\\n",
    "#         str(len(py_training_samples)) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the table arrays and copying the labels data inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_crop =12\n",
      "bottom_crop =43\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping (Cropping2D)        (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 35, 62, 24)        1824      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 16, 29, 36)        21636     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 6, 13, 48)         43248     \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 4, 11, 64)         27712     \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 2, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape, LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "print ( \"top_crop =\" + str(top_crop))\n",
    "print ( \"bottom_crop =\" + str(bottom_crop))\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. )) #, input_shape = (resized_shape,resized_shape,3)))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "# model.add(LeakyReLU(alpha=.001))   # add an advanced activation\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu'))\n",
    "\n",
    "model.add(Dense(50, activation='elu'))\n",
    "\n",
    "model.add(Dense(10, activation='elu'))\n",
    "\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining thread safe generator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import threading\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def generator(samples, labels, batch_size ):\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 200))\n",
    "# #     plt.subplot(50, 4, 1 )\n",
    "#     plt.axis('off')\n",
    "#     for i, image in enumerate(py_training_samples_part1):\n",
    "#            plt.subplot(50, 4, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            plt.imshow(image, cmap='gray')\n",
    "#     plt.show()  \n",
    "    read_nb = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        \n",
    "        for offset in range(0, len(samples), 32):\n",
    "            images = []\n",
    "            angles=[]\n",
    "#             print ( \"offset = \" +str(offset))\n",
    "            for image, steering in zip(samples[offset:offset+32],labels[offset:offset+32]):\n",
    "                images.append(image)\n",
    "                angles.append(steering)\n",
    "\n",
    "            yield np.array(images) , np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9546, 128, 128, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the traing_generator uses Queue and async thread !\n",
    "train_generator      = generator(training_samples, \n",
    "                                 training_steerings, \n",
    "                                 32)\n",
    "\n",
    "validation_generator = generator(validation_samples, \n",
    "                                 validation_steerings, \n",
    "                                 batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0960 - val_loss: 0.0452\n",
      "Epoch 2/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0973 - val_loss: 0.0452\n",
      "Epoch 3/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0937 - val_loss: 0.0452\n",
      "Epoch 4/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0937 - val_loss: 0.0452\n",
      "Epoch 5/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0938 - val_loss: 0.0452\n",
      "Epoch 6/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0939 - val_loss: 0.0452\n",
      "Epoch 7/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0941 - val_loss: 0.0452\n",
      "Epoch 8/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0942 - val_loss: 0.0452\n",
      "Epoch 9/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 10/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 11/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 12/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 13/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 14/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 15/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 16/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 17/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 18/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 19/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 20/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 21/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 22/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 23/30\n",
      "1194/1193 [==============================] - 11s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 24/30\n",
      "1194/1193 [==============================] - 12s - loss: 0.0943 - val_loss: 0.0452\n",
      "Epoch 25/30\n",
      "1193/1193 [============================>.] - ETA: 0s - loss: 0.0943"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(training_samples)\n",
    "number_of_validation_samples = len(validation_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "                                     numper_of_train_samples/32, \n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     validation_steps=number_of_validation_samples/32, \n",
    "                                     epochs=epochs, verbose = 1,\\\n",
    "                                     workers=2)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"selfdrive_model.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to selfdrive_model.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "# print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print (\" Loading drive.h5 .......\")\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.models import Model\n",
    "\n",
    "# modelobj = load_model('drive.h5')\n",
    "# print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(py_training_samples_part1[3000], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Load test images\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# test_images = []\n",
    "\n",
    "# image = cv2.imread('./test_images/center1.jpg')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "# test_images.append(image)\n",
    "\n",
    "\n",
    "# test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'cropping'\n",
    "# intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "#                                  outputs=modelobj.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Show the cropped images\n",
    "# def show_intermediate_output(image_ori, intermediate_output):\n",
    "#     print (intermediate_output.shape)\n",
    "#     depth = 0 \n",
    "#     %matplotlib inline\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     plt.figure(figsize=(20, 100))\n",
    "#     new_image = []\n",
    "#     plt.subplot(40, 5, 1 )\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image_ori)\n",
    "#     for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "#            single_output = intermediate_output[:,:,i]\n",
    "# #            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "# #            print ( single_output)\n",
    "#            plt.subplot(40, 5, i+2 )\n",
    "#            plt.axis('off')\n",
    "#            single_output = single_output.astype(np.uint8)\n",
    "#            plt.imshow(single_output, cmap='gray')\n",
    "#     plt.show()    \n",
    "\n",
    "    \n",
    "# show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv1'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv2'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv3'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Call the model to calculate an intermediate layer using the test images\n",
    "# layer_name = 'Conv4'\n",
    "# intermediate_layer_model = Model(input=model.input,\n",
    "#                                  output=model.get_layer(layer_name).output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "# int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "# show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from keras.utils.visualize_util import plot\n",
    "# from keras.models import load_model\n",
    "# %matplotlib inline\n",
    "\n",
    "# #visualize the model\n",
    "# modelobj = load_model('model.h5')\n",
    "# plot (modelobj, to_file='model.png')\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(100, 100))\n",
    "# image = cv2.imread('model.png')\n",
    "# image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "# plt.subplot(5, 5, 1)\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
