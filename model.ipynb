{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the .csv containing the file names and the steering angles\n",
    "\n",
    "### Loading the file names  and steering angles into samples\n",
    "### Splitting samples into train and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  extractFileName ( abs_path):\n",
    "\n",
    "    import os\n",
    "    if os.name == \"nt\":\n",
    "        split_char = '\\\\' \n",
    "    else:\n",
    "        split_char = '/' \n",
    "    if '\\\\' in abs_path:\n",
    "        # \"  Windows Path \" \n",
    "        image_name = abs_path.split ('\\\\')[-3] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-2] \\\n",
    "                            + split_char + abs_path.split ('\\\\')[-1]\n",
    "\n",
    "    else:\n",
    "        # \"  Unix Path \" \n",
    "        image_name = abs_path.split ('/')[-3] \\\n",
    "                            + split_char + abs_path.split ('/')[-2] \\\n",
    "                            + split_char + abs_path.split ('/')[-1]\n",
    "    \n",
    "    return image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the resize shape of the images ( this parameter will be used also in the Generator and in the Model definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_shape = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the batch size:\n",
    "batch_size = 32\n",
    "\n",
    "### Defining the Queue loader chunk size  \n",
    "queue_loader_chunk = 1000 # batch_size(32) * 1000 samples, = 32000 images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the PyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = open_file(\"./data/samples.hdf5\", mode = \"w\", title = \"Samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the two objects as images container:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_samples = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                    'train_img', \\\n",
    "                    tables.UInt8Atom(), \\\n",
    "                    shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk ,32,32,3))\n",
    "\n",
    "py_validation_samples      = hdf5_file.create_earray(hdf5_file.root, \\\n",
    "                     'val_img', tables.UInt8Atom(), \\\n",
    "                     shape=( 0,resized_shape, resized_shape, 3),chunkshape=(batch_size*queue_loader_chunk,32,32,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting .... \n",
      "Reading from logfile = ./data/track2_run1.csv\n",
      "Reading from logfile = ./data/run5.csv\n",
      "Reading from logfile = ./data/run6.csv\n",
      "Reading from logfile = ./data/track2_run4.csv\n",
      "Reading from logfile = ./data/track2_run2.csv\n",
      "Reading from logfile = ./data/run2.csv\n",
      "Reading from logfile = ./data/run1.csv\n",
      "Reading from logfile = ./data/track2_run3.csv\n",
      "Reading from logfile = ./data/run4.csv\n",
      "Reading from logfile = ./data/runx.csv\n",
      "Reading from logfile = ./data/run3.csv\n",
      "Reading from logfile = ./data/run7.csv\n",
      "Reading from logfile = ./data/run9.csv\n",
      "\n",
      "\n",
      "There are 18713 images in total \n",
      "....splitted into training images = 14970  \n",
      "                  val images      = 3743  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting .... \")\n",
    "samples_list = []\n",
    "center_image_before = None\n",
    "for name in glob.glob(\"./data/*.csv\"):\n",
    "    print ( \"Reading from logfile = \" + name)\n",
    "    with open(name)  as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            for line in reader:\n",
    "                # STEERING ANGLE CALCULATION\n",
    "                samples_list.append([extractFileName( line[0]),\\\n",
    "                                     extractFileName( line[1]),\\\n",
    "                                     extractFileName( line[2]),\\\n",
    "                                     float(line[3])])\n",
    "                \n",
    "samples_list = np.array(samples_list)\n",
    "\n",
    "from random import shuffle\n",
    "shuffle(samples_list)\n",
    "\n",
    "train_list = samples_list[0:int(0.8*len(samples_list))]\n",
    "\n",
    "val_list = samples_list[int(0.8*len(samples_list)):int(1.0*len(samples_list))]\n",
    "\n",
    "\n",
    "print (\"\\n\\nThere are {} images in total \".format(len(samples_list)))\n",
    "print (\"....splitted into training images = {}  \".format(len(train_list)))\n",
    "print (\"                  val images      = {}  \".format(len(val_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list = train_list[0:100 ]\n",
    "# train_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(line):\n",
    "        preprocessed_samples=[]\n",
    "        # STEERING ANGLE CALCULATION\n",
    "        correction = 0.03 # this is a parameter to tune\n",
    "        center_steering = float(line[3])\n",
    "        left_steering   = center_steering + correction\n",
    "        right_steering  = center_steering - correction\n",
    "\n",
    "        # CENTER IMAGE\n",
    "        center_image = cv2.imread(extractFileName( line[0]))\n",
    "        center_image = cv2.cvtColor (center_image, cv2.COLOR_BGR2RGB)\n",
    "        center_image = cv2.resize(center_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([center_image, center_steering ])\n",
    "\n",
    "        #   LEFT IMAGE\n",
    "        left_image = cv2.imread(extractFileName( line[1]))\n",
    "        left_image = cv2.cvtColor (left_image, cv2.COLOR_BGR2RGB)\n",
    "        left_image = cv2.resize(left_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([left_image, left_steering ])\n",
    "\n",
    "        #   RIGHT IMAGE\n",
    "        right_image = cv2.imread(extractFileName( line[2]))\n",
    "        right_image = cv2.cvtColor (right_image, cv2.COLOR_BGR2RGB)\n",
    "        right_image = cv2.resize(right_image,(resized_shape,resized_shape ))\n",
    "        preprocessed_samples.append([right_image, right_steering ])\n",
    "\n",
    "\n",
    "        ###\n",
    "        ### IMAGE AUGMENTATION\n",
    "        ###\n",
    "        # augmented center image\n",
    "        preprocessed_samples.append([cv2.flip(center_image,1), center_steering*-1.0 ])\n",
    "\n",
    "        # augmented left image\n",
    "        preprocessed_samples.append([cv2.flip(left_image  ,1), left_steering  *-1.0] )\n",
    "\n",
    "        # augmented right image\n",
    "        preprocessed_samples.append([cv2.flip(right_image,1),  right_steering *-1.0] )\n",
    "        \n",
    "#         print ( \"here 1 {}\".format( np.array(preprocessed_samples).shape))\n",
    "        return np.array(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image preprocessing using the function defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Preprocessing the images  .... \n",
      ".. training samples processed 1000\n",
      ".. training samples processed 2000\n",
      ".. training samples processed 3000\n",
      ".. training samples processed 4000\n",
      ".. training samples processed 5000\n",
      ".. training samples processed 6000\n",
      ".. training samples processed 7000\n",
      ".. training samples processed 8000\n",
      ".. training samples processed 9000\n",
      ".. training samples processed 10000\n",
      ".. training samples processed 11000\n",
      ".. training samples processed 12000\n",
      ".. training samples processed 13000\n",
      ".. training samples processed 14000\n",
      ".. validation samples processed 1000\n",
      ".. validation samples processed 2000\n",
      ".. validation samples processed 3000\n",
      "\n",
      "Total training samples 128x128 after augmentation and preprocessing : 89820 \n",
      "\n",
      "Total validation samples 128x128 after augmentation and preprocessing : 22458 \n",
      "... completed\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "print ( \"Starting Preprocessing the images  .... \")\n",
    "train_samples      =  np.array([]).reshape(0,2)\n",
    "validation_samples =  np.array([]).reshape(0,2)\n",
    "training_steering = []\n",
    "val_steering = []\n",
    "\n",
    "for i,sample_line in enumerate(train_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print (output[0].shape)\n",
    "        py_training_samples.append(output[0][None])\n",
    "        training_steering.append(output[1])\n",
    "          \n",
    "   if i% 1000 == 0 and i> 0 : print(\".. training samples processed {}\".format(i))     \n",
    "   \n",
    "for i,sample_line in enumerate(val_list):\n",
    "   for output in data_preprocess(sample_line):\n",
    "#         print ( \"output[0].shape\" + str(output[0].shape))\n",
    "        py_validation_samples.append(output[0][None])\n",
    "        val_steering.append(output[1])\n",
    "#         print (output[0][None].shape)\n",
    "\n",
    "   if i% 1000 == 0 and i> 0 : print(\".. validation samples processed {}\".format(i))     \n",
    "\n",
    "\n",
    "print (\"\\nTotal training samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_training_samples)) ))\n",
    "print (\"\\nTotal validation samples {}x{} after augmentation and preprocessing : {} \"\\\n",
    "       .format(resized_shape,resized_shape,\\\n",
    "        str(len(py_validation_samples)) ))\n",
    "print ( \"... completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the table arrays and copying the labels data inside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings = hdf5_file.create_array(hdf5_file.root, 'py_training_steering',training_steering )\n",
    "py_validation_steerings = hdf5_file.create_array(hdf5_file.root, 'py_val_steering', val_steering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring the dataset ...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1504dea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa1504de9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the dataset complete.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "print(\"\\nExploring the dataset ...\")\n",
    " \n",
    "# It plots the histogram of an arrray of angles: [0.0,0.1, ..., -0.1]\n",
    "def plot_steering_histogram(steerings, title, num_bins=100):\n",
    "    plt.hist(steerings, num_bins)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Steering Angles')\n",
    "    plt.ylabel('# Images')\n",
    "    plt.show()\n",
    " \n",
    "# # It plots the histogram of an arrray of associative arrays of angles: [{'steering':0.1}, {'steering':0.2}, ..., {'steering':-0.1}]\n",
    "def plot_dataset_histogram(samples, title, num_bins=100):\n",
    "    steerings = []\n",
    "    for item in samples:\n",
    "#         print (item)\n",
    "        steerings.append( float(item) )\n",
    "    plot_steering_histogram(steerings, title, num_bins)\n",
    "\n",
    "samples_before = samples_list[:,3]\n",
    "# Plot the histogram of steering angles before the image augmentation\n",
    "plot_dataset_histogram(samples_before, 'Images per steering angle BEFORE AUGMENTATION', num_bins=100)\n",
    "samples_before = []\n",
    "\n",
    "# Plot the histogram of steering angles after the image augmentation\n",
    "plot_dataset_histogram(training_steering, 'Images per steering angle AFTER AUGMENTATION', num_bins=100)\n",
    "print(\"Exploring the dataset complete.\")\n",
    "samples=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition using Keras\n",
    "\n",
    "#### NVIDIA model used\n",
    "#### Image normalization to avoid saturation and make gradients work better.\n",
    "####     Convolution: 5x5, filter: 24, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 36, strides: 2x2, activation: ELU\n",
    "####     Convolution: 5x5, filter: 48, strides: 2x2, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Convolution: 3x3, filter: 64, strides: 1x1, activation: ELU\n",
    "####     Drop out (0.5)\n",
    "####     Fully connected: neurons: 100, activation: ELU\n",
    "####     Fully connected: neurons: 50, activation: ELU\n",
    "####     Fully connected: neurons: 10, activation: ELU\n",
    "####     Fully connected: neurons: 1 (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping (Cropping2D)        (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 73, 128, 3)        0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 35, 62, 24)        1824      \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 16, 29, 36)        21636     \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 6, 13, 48)         43248     \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 4, 11, 64)         27712     \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 2, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               115300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Activation, Dropout, Reshape\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "top_crop = int(resized_shape*10/100)\n",
    "bottom_crop = int(resized_shape*34/100)\n",
    "\n",
    "# Data Preprocessing ( Normalization and mean centering)\n",
    "model.add(Cropping2D(cropping =((bottom_crop,top_crop),(0,0)), input_shape = (resized_shape,resized_shape,3), name =\"cropping\") )\n",
    "model.add(Lambda(lambda x: x/127.5 - 1. , input_shape = (resized_shape,resized_shape,3)))\n",
    "\n",
    "model.add(Conv2D(24, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv1\"))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv2\"))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5), activation='elu', padding='valid',strides=(2, 2), name = \"Conv3\"))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv4\"))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu', padding='valid',strides=(1, 1), name = \"Conv5\"))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(50, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(10, activation='elu',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Dense(1,kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the generators .\n",
    "### This flushes the files content from disk and return it to Tensorflow for the training fit\n",
    "### The generator is repeated many times ( as many Epochs of training )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Queue Thread process\n",
    "#### Here I am creating a function that will be called in a separate thread . This simply read big Chunks from Disk ( also the Pytable ) , shuffle them, and make them at disposition of a further processer in a Python Queue.\n",
    "#### The size of this two Queue , samples_q and labels_q is defined as batch_size * 100, so for example 3200 samples\n",
    "#### The great thing about Python Queue is that , if we define the maxsize, the put instruction in case the Queue is full, will wait until will be some space free. \n",
    "#### **** This is useful to AVOID TO LOAD THE ENTIRE PYTABLE IN MEMORY ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the  Pytable into two different table with 50/50% number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdf5_file_part1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6863b04a0eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhdf5_file_part1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhdf5_file_part2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# hdf5_file.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hdf5_file_part1' is not defined"
     ]
    }
   ],
   "source": [
    "hdf5_file_part1.close()\n",
    "hdf5_file_part2.close()\n",
    "# hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tables import *\n",
    "import tables\n",
    "\n",
    "hdf5_file_part1 = open_file(\"./data/samples_part1.hdf5\", mode = \"w\", title = \"Samples_part1\")\n",
    "py_training_samples_part1       = hdf5_file_part1.create_earray(hdf5_file_part1.root, \\\n",
    "                                'train_img', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "py_validation_samples_part1      = hdf5_file_part1.create_earray(hdf5_file_part1.root, \\\n",
    "                                 'val_img', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second file ( if you have a second SSD this can be put on a different Disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file_part2 = open_file(\"./data/samples_part2.hdf5\", mode = \"w\", title = \"Samples_part1\")\n",
    "py_training_samples_part2       = hdf5_file_part1.create_earray(hdf5_file_part2.root, \\\n",
    "                                'train_img', \\\n",
    "                                tables.UInt8Atom(), \\\n",
    "                                shape=( 0,resized_shape, resized_shape, 3))\n",
    "\n",
    "py_validation_samples_part2      = hdf5_file_part1.create_earray(hdf5_file_part2.root, \\\n",
    "                                 'val_img', tables.UInt8Atom(), \\\n",
    "                                 shape=( 0,resized_shape, resized_shape, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the py_training_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Training Samples......\n",
      "... completed\n",
      "\n",
      "Training Sample table before splitting . Nrecords = 89820\n",
      "               py_training_samples_part1 Nrecords = 44910\n",
      "               py_training_samples_part1 Nrecords = 44910\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Training Samples......\")\n",
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "\n",
    "for i, training_sample in enumerate(py_training_samples):\n",
    "    if i < n_rec_tr_1:\n",
    "        py_training_samples_part1.append(training_sample[None])\n",
    "    else:\n",
    "        py_training_samples_part2.append(training_sample[None])\n",
    "print ( \"... completed\")\n",
    "\n",
    "print ( \"\\nTraining Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part1)))\n",
    "print ( \"               py_training_samples_part1 Nrecords = {}\".format(len(py_training_samples_part2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Splitting the py_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Start splitting Validation Samples......\n",
      "... completed\n",
      "\n",
      "Validation Sample table before splitting . Nrecords = 22458\n",
      "               py_validation_samples_part1   Nrecords = 11229\n",
      "               py_validation_samples_part2   Nrecords = 11229\n"
     ]
    }
   ],
   "source": [
    "print ( \" Start splitting Validation Samples......\")\n",
    "n_rec = len(py_validation_samples)\n",
    "\n",
    "n_rec_val_1 =  int(n_rec * 0.5)\n",
    "n_rec_val_2 = n_rec - n_rec_val_1\n",
    "\n",
    "for i, validation_sample in enumerate(py_validation_samples):\n",
    "    if i < n_rec * 0.5:\n",
    "        py_validation_samples_part1.append(validation_sample[None])\n",
    "    else:\n",
    "        py_validation_samples_part2.append(validation_sample[None])\n",
    "print ( \"... completed\")\n",
    "\n",
    "print ( \"\\nValidation Sample table before splitting . Nrecords = {}\".format(n_rec))\n",
    "print ( \"               py_validation_samples_part1   Nrecords = {}\".format(len(py_validation_samples_part1)))\n",
    "print ( \"               py_validation_samples_part2   Nrecords = {}\".format(len(py_validation_samples_part2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the steerings angle... the training labels and validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44910"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rec = len(py_training_samples)\n",
    "n_rec_tr_1 =  int(n_rec * 0.5)\n",
    "n_rec_tr_2 = n_rec - n_rec_tr_1\n",
    "n_rec_tr_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part1 = hdf5_file_part1.create_array(\n",
    "                               hdf5_file_part1.root, \n",
    "                              'py_training_steering',\n",
    "                               training_steering[0:n_rec_tr_1]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_training_steerings_part2 = hdf5_file_part2.create_array(\n",
    "                               hdf5_file_part2.root, \n",
    "                              'py_training_steering',\n",
    "                               training_steering[n_rec_tr_1:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels table before splitting . Nrecords = 89820\n",
      "               py_training_steerings_part1   Nrecords = 44910\n",
      "               py_training_steerings_part2   Nrecords = 44910\n"
     ]
    }
   ],
   "source": [
    "print ( \"Training Labels table before splitting . Nrecords = {}\".format(len(training_steering)))\n",
    "print ( \"               py_training_steerings_part1   Nrecords = {}\".format(len(py_training_steerings_part1)))\n",
    "print ( \"               py_training_steerings_part2   Nrecords = {}\".format(len(py_training_steerings_part2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part1 = hdf5_file_part1.create_array(\n",
    "                               hdf5_file_part1.root, \n",
    "                              'py_validation_steering',\n",
    "                               val_steering[0:n_rec_val_1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_validation_steerings_part2 = hdf5_file_part2.create_array(\n",
    "                               hdf5_file_part2.root, \n",
    "                              'py_validation_steering',\n",
    "                               val_steering[n_rec_val_1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Labels table before splitting . Nrecords = 22458\n",
      "               py_validation_steerings_part1   Nrecords = 11229\n",
      "               py_validation_steerings_part2   Nrecords = 11229\n"
     ]
    }
   ],
   "source": [
    "print ( \"Validation Labels table before splitting . Nrecords = {}\".format(len(val_steering)))\n",
    "print ( \"               py_validation_steerings_part1   Nrecords = {}\".format(len(py_validation_steerings_part1)))\n",
    "print ( \"               py_validation_steerings_part2   Nrecords = {}\".format(len(py_validation_steerings_part2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from time import sleep \n",
    "\n",
    "def read_images_into_queue(samples_q, labels_q , samples, labels):\n",
    "#     print ( \" reading images into Queue\")\n",
    "    # Define the Queue max size , the Queue.put() automatically do wait until records will be get from \n",
    "    # an other process and will free some space in the queue.\n",
    "#     From docs.python.org:\n",
    "#     The Queue module implements multi-producer, multi-consumer queues. \n",
    "#     It is especially useful in threaded programming when information must be exchanged safely between multiple threads. \n",
    "#     The Queue class in this module implements all the required locking semantics. \n",
    "#     It depends on the availability of thread support in Python; see the threading module.\n",
    "    \n",
    "    numsamples = len(samples)\n",
    "    while 1:  ### remember you need to stop the process !!\n",
    "#         print (\"numsamples = \" + str(numsamples))\n",
    "        for offset in range(0, numsamples, batch_size*queue_loader_chunk):\n",
    "#              print ( \"offset = \" + str(offset))\n",
    "             # loading into memory a BIG chunk of data ( 32* queue_loader_chunk  )\n",
    "             chunk_batch_samples = samples[offset:offset+batch_size*queue_loader_chunk]\n",
    "             chunk_batch_labels  = labels[offset:offset+batch_size*queue_loader_chunk]\n",
    "#              print (\"chunk_batch_samples size {}\".format(chunk_batch_samples.shape) )\n",
    "             # shuffle the chunk\n",
    "             chunk_batch_samples,chunk_batch_labels = sklearn.utils.shuffle(chunk_batch_samples,chunk_batch_labels)  \n",
    "#              sleep (0.1)\n",
    "             for sample, steering in zip ( chunk_batch_samples,chunk_batch_labels):\n",
    "                samples_q.put(sample)\n",
    "                labels_q.put(steering)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Starting the reading processes -- from Disk to Memory Queue\n",
    "#### Remember to TERMINATE them !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "training_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "training_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "validation_samples_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "validation_labels_q = Queue(maxsize = batch_size * queue_loader_chunk)\n",
    "\n",
    "###############################################################\n",
    "# Training Producers . They load training data into Queues\n",
    "###############################################################\n",
    "training_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings_part1))        # <-- Training labels  Pytable\n",
    "training_producer1.start()\n",
    "\n",
    "training_producer2 = Process(target=read_images_into_queue, \n",
    "                            args=(training_samples_q,            # <-- Training images queue\n",
    "                                  training_labels_q,             # <-- Training labels queue\n",
    "                                  py_training_samples_part2,           # <-- Training samples Pytable\n",
    "                                  py_training_steerings_part2))        # <-- Training labels  Pytable\n",
    "training_producer2.start()\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Validation Producers. They load validation data into Queues\n",
    "###############################################################\n",
    "validation_producer1 = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples_part1,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings_part1))        # <-- Training labels  Pytable\n",
    "validation_producer1.start()\n",
    "\n",
    "validation_producer2 = Process(target=read_images_into_queue, \n",
    "                            args=(validation_samples_q,              # <-- Training images queue\n",
    "                                  validation_labels_q,               # <-- Training labels queue\n",
    "                                  py_validation_samples_part2,           # <-- Training samples Pytable\n",
    "                                  py_validation_steerings_part2))        # <-- Training labels  Pytable\n",
    "validation_producer2.start()\n",
    "\n",
    "\n",
    "## training_producer1.terminate()\n",
    "## training_producer2.terminate()\n",
    "\n",
    "## validation_producer1.terminate()\n",
    "## validation_producer2.terminate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Defining thread safe generator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import threading\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n",
    "\n",
    "@threadsafe_generator\n",
    "def generator(samples_q, labels_q, batch_size ):\n",
    "    read_nb = 0\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        \n",
    "        images = []\n",
    "        angles=[]\n",
    "        for i in range(0, batch_size):\n",
    "            images.append(samples_q.get())\n",
    "            angles.append(labels_q.get())\n",
    "\n",
    "        yield np.array(images) , np.array(angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Train and Validation generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that the traing_generator uses Queue and async thread !\n",
    "train_generator      = generator(training_samples_q, \n",
    "                                 training_labels_q, \n",
    "                                 batch_size)\n",
    "\n",
    "validation_generator = generator(validation_samples_q, \n",
    "                                 validation_labels_q, \n",
    "                                 batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model using traing_generator and validating with validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2807/2806 [==============================] - 29s - loss: 0.1330 - val_loss: 0.0879\n",
      "Epoch 2/5\n",
      "2807/2806 [==============================] - 29s - loss: 0.1297 - val_loss: 0.0839\n",
      "Epoch 3/5\n",
      "2807/2806 [==============================] - 29s - loss: 0.1354 - val_loss: 0.0855\n",
      "Epoch 4/5\n",
      "2807/2806 [==============================] - 29s - loss: 0.1278 - val_loss: 0.0859\n",
      "Epoch 5/5\n",
      "2807/2806 [==============================] - 29s - loss: 0.1273 - val_loss: 0.0878\n",
      "\n",
      "Total number of train samples: 89820 ( shape 128x128)\n",
      "\n",
      "Batch Size                   : 32\n",
      "\n",
      "Duration                     : 0:02:27.939784\n",
      "  \n",
      " .. model saved to selfdrive_model.h5 \n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCJRwhARkUiUMEREJJL/Hz5rvgTkwryyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa14cfaaeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "numper_of_train_samples      = len(py_training_samples)\n",
    "number_of_validation_samples = len(py_validation_samples) \n",
    "\n",
    "history_object = model.fit_generator(train_generator, steps_per_epoch= \\\n",
    "                                     numper_of_train_samples/batch_size, \n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     validation_steps=number_of_validation_samples/batch_size, \n",
    "                                     epochs=epochs, verbose = 1,\\\n",
    "                                     workers=2)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('\\nTotal number of train samples: {} ( shape {}x{})'.format(numper_of_train_samples,resized_shape,resized_shape))\n",
    "print('\\nBatch Size                   : {}'.format(batch_size))\n",
    "print('\\nDuration                     : {}'.format(end_time - start_time))\n",
    "\n",
    "from keras.models import save_model\n",
    "\n",
    "save_model(model, \"selfdrive_model.h5\")\n",
    "print ( \"  \")\n",
    "print ( \" .. model saved to selfdrive_model.h5 \")\n",
    "print ( \"  \")\n",
    "\n",
    "\n",
    "### print the keys contained in the history object\n",
    "# print(history_object.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# # # Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_producer1.terminate()\n",
    "training_producer2.terminate()\n",
    "\n",
    "validation_producer1.terminate()\n",
    "validation_producer2.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Convolution broken down in small pieces \n",
    "\n",
    "### Here I am trying to visualize the Convolution Layers to understand visually how many filters I should use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (\" Loading drive.h5 .......\")\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "modelobj = load_model('drive.h5')\n",
    "print (\" ..... model drive.h5 successfully loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this purpose I am loading a Test image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load test images\n",
    "import cv2\n",
    "import numpy as np\n",
    "test_images = []\n",
    "\n",
    "image = cv2.imread('./test_images/center1.jpg')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image,(resized_shape,resized_shape ))     \n",
    "test_images.append(image)\n",
    "\n",
    "\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First of all I am looking at the Image Crop if is well done in the right position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'cropping'\n",
    "intermediate_layer_model = Model(inputs=modelobj.input,\n",
    "                                 outputs=modelobj.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "intermediate_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the cropped images\n",
    "def show_intermediate_output(image_ori, intermediate_output):\n",
    "    print (intermediate_output.shape)\n",
    "    depth = 0 \n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(20, 100))\n",
    "    new_image = []\n",
    "    plt.subplot(40, 5, 1 )\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image_ori)\n",
    "    for i in range(0,intermediate_output[0,0].shape[0]):\n",
    "           single_output = intermediate_output[:,:,i]\n",
    "#            print ( \"single_output.shape {}\".format(single_output.shape ))\n",
    "#            print ( single_output)\n",
    "           plt.subplot(40, 5, i+2 )\n",
    "           plt.axis('off')\n",
    "           single_output = single_output.astype(np.uint8)\n",
    "           plt.imshow(single_output, cmap='gray')\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "show_intermediate_output(test_images[0], intermediate_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the FIRST convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv1'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now the SECOND convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv2'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv3'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model to calculate an intermediate layer using the test images\n",
    "layer_name = 'Conv4'\n",
    "intermediate_layer_model = Model(input=model.input,\n",
    "                                 output=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(test_images)\n",
    "int_unNorm = (intermediate_output[0]+1) * 127.5\n",
    "show_intermediate_output(test_images[0], int_unNorm ) \n",
    "                            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.models import load_model\n",
    "%matplotlib inline\n",
    "\n",
    "#visualize the model\n",
    "modelobj = load_model('model.h5')\n",
    "plot (modelobj, to_file='model.png')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(100, 100))\n",
    "image = cv2.imread('model.png')\n",
    "image = cv2.cvtColor (image, cv2.COLOR_BGR2RGB)\n",
    "plt.subplot(5, 5, 1)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
